{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CLASSIFICATORE LINEARE SVM CON INPUT DI N-GRAMMI\n",
    "\n",
    "Classificatore basato su  SVM che prende in input una matrice di features basata su n-grammi di 3 tipi:\n",
    "1. Caratteri\n",
    "2. Token\n",
    "3. Part of Speech\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing dei dati\n",
    "\n",
    "Dobbiamo ottenere un vettore di features, basato sulle occorrenze di n-grammi all'interno delle frasi, per ciascun post. Come prima cosa si crea si per training che per test un set formato da liste di dizionari. I dizionari riportano per ogni token 3 campi che corrispondono alla parola, la forma lemmatizzata e la parte del discorso. Infine contiamo all'interno dei post le occorrenze degli n-grammi. Una volta ottenuti tutti gli n-grammi possiamo creare la matrice di occorrenze. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bergo\\Desktop\\Uni\\LCII_Project\\LCII_project\\2_svmLXFT\\project_2.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bergo/Desktop/Uni/LCII_Project/LCII_project/2_svmLXFT/project_2.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m             annotated_posts\u001b[39m.\u001b[39mappend(doc_tokens)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bergo/Desktop/Uni/LCII_Project/LCII_project/2_svmLXFT/project_2.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m annotated_posts\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bergo/Desktop/Uni/LCII_Project/LCII_project/2_svmLXFT/project_2.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m annotation_tr \u001b[39m=\u001b[39m create_set(\u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bergo/Desktop/Uni/LCII_Project/LCII_project/2_svmLXFT/project_2.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m annotation_ts \u001b[39m=\u001b[39m create_set(\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\bergo\\Desktop\\Uni\\LCII_Project\\LCII_project\\2_svmLXFT\\project_2.ipynb Cell 4\u001b[0m in \u001b[0;36mcreate_set\u001b[1;34m(type)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bergo/Desktop/Uni/LCII_Project/LCII_project/2_svmLXFT/project_2.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m doc_tokens \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bergo/Desktop/Uni/LCII_Project/LCII_project/2_svmLXFT/project_2.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m doc_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../data/UD_annotation/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m doc\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bergo/Desktop/Uni/LCII_Project/LCII_project/2_svmLXFT/project_2.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m \u001b[39mopen\u001b[39;49m(doc_path, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bergo/Desktop/Uni/LCII_Project/LCII_project/2_svmLXFT/project_2.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     splitted \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39mstrip()\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bergo/Desktop/Uni/LCII_Project/LCII_project/2_svmLXFT/project_2.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mif\u001b[39;00m splitted[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39misdigit() \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m splitted[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\bergo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\codecs.py:309\u001b[0m, in \u001b[0;36mBufferedIncrementalDecoder.__init__\u001b[1;34m(self, errors)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mBufferedIncrementalDecoder\u001b[39;00m(IncrementalDecoder):\n\u001b[0;32m    304\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001b[39;00m\n\u001b[0;32m    306\u001b[0m \u001b[39m    incremental decoder if the decoder must be able to handle incomplete\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[39m    byte sequences.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 309\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    310\u001b[0m         IncrementalDecoder\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, errors)\n\u001b[0;32m    311\u001b[0m         \u001b[39m# undecoded input that is kept between calls to decode()\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#creiamo un dizionario che abbia 3 campi: word, lemma e part of speech(pos)\n",
    "def create_set(type):\n",
    "    annotated_posts = []\n",
    "    for doc in os.listdir(\"../data/UD_annotation\"):\n",
    "        if type in doc: \n",
    "            doc_tokens = []\n",
    "            doc_path = \"../data/UD_annotation/\" + doc\n",
    "            for line in open(doc_path, \"r\", encoding=\"utf-8\"):\n",
    "                splitted = line.strip().split(\"\\t\")\n",
    "                if splitted[0].isdigit() and \"-\" not in splitted[0]:\n",
    "                    word=splitted[1]\n",
    "                    lemma=splitted[2]\n",
    "                    pos=splitted[3]\n",
    "                    new_token = {'word': word, 'lemma': lemma, 'pos': pos}\n",
    "                    doc_tokens.append(new_token)\n",
    "            annotated_posts.append(doc_tokens)\n",
    "    return annotated_posts\n",
    "\n",
    "annotation_tr = create_set(\"training\")\n",
    "annotation_ts = create_set(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che estrae le labels dal nome del file\n",
    "def create_labels(type):\n",
    "    labels = []\n",
    "    for doc in os.listdir(\"../data/UD_annotation\"):\n",
    "        if type in doc: \n",
    "            splitted = doc.split(\"#\")\n",
    "            irony = splitted[2]\n",
    "            labels.append(irony)\n",
    "    return labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 3977\n",
      "Test: 872\n"
     ]
    }
   ],
   "source": [
    "#contiamo il numero di post(sample) per training e test\n",
    "print(f'Training: {len(annotation_tr)}')\n",
    "print(f'Test: {len(annotation_ts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word_2_#la7_ma': 0.05555555555555555, 'word_2_ma_perche': 0.05555555555555555, \"word_2_perche_'\": 0.05555555555555555, \"word_2_'_Mario\": 0.05555555555555555, 'word_2_Mario_Monti': 0.05555555555555555, 'word_2_Monti_non': 0.05555555555555555, 'word_2_non_fa': 0.05555555555555555, 'word_2_fa_il': 0.05555555555555555, 'word_2_il_premier': 0.05555555555555555, 'word_2_premier_?': 0.05555555555555555, 'word_2_?_Che': 0.05555555555555555, 'word_2_Che_persona': 0.05555555555555555, 'word_2_persona_competente': 0.05555555555555555, 'word_2_competente_e': 0.05555555555555555, 'word_2_e_per': 0.05555555555555555, 'word_2_per_bene': 0.05555555555555555, 'word_2_bene_!': 0.05555555555555555}\n"
     ]
    }
   ],
   "source": [
    "#funzione che conta le occorrenze degli ngrammi all'interno di un post\n",
    "def count_ngrams(post, ft_type, n, char=False):\n",
    "    all_ngrams = {}\n",
    "    allwords = []\n",
    "    #se char = True la lista sarà di caratteri, altrimenti sarà di token\n",
    "    if not char:\n",
    "        for word in post:\n",
    "            allwords.append(word[ft_type])\n",
    "        post_length = len(allwords)\n",
    "    else:\n",
    "        for word in post:\n",
    "            allwords.append(word['word'])\n",
    "        allwords = \" \".join(allwords)\n",
    "        post_length = len(allwords)-1\n",
    "    #si da un id agli n-grammi e si contano le occorrenze nel post \n",
    "    for i in range(len(allwords)-(n-1)):\n",
    "        new_ngram = allwords[i:i+n]\n",
    "        if not char:\n",
    "            ngram_id = f'{ft_type}_{n}_'+'_'.join(new_ngram)\n",
    "        else:\n",
    "            ngram_id = f'char_{n}_'+'_'.join(new_ngram)\n",
    "        if ngram_id not in all_ngrams:\n",
    "            all_ngrams[ngram_id] = 1\n",
    "        else:\n",
    "            all_ngrams[ngram_id]+=1\n",
    "    #normalizzare in base alla post_length\n",
    "    for ngram in all_ngrams:\n",
    "        all_ngrams[ngram] = all_ngrams[ngram]/post_length\n",
    "    return all_ngrams\n",
    "\n",
    "print(count_ngrams(annotation_tr[2], \"word\", 2, False))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniamo per ogni tipo di informazione che vogliamo i relativi dizionari, così da avere un dizionario denso di informazioni. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word_1_Mario': 0.043478260869565216, 'word_1_Monti': 0.043478260869565216, 'word_1_:': 0.043478260869565216, \"word_1_c'\": 0.043478260869565216, 'word_1_è': 0.043478260869565216, 'word_1_il': 0.043478260869565216, 'word_1_rischio...': 0.043478260869565216, 'word_1_di': 0.08695652173913043, 'word_1_trasformare': 0.043478260869565216, \"word_1_l'\": 0.08695652173913043, 'word_1_Italia': 0.043478260869565216, 'word_1_da': 0.043478260869565216, 'word_1_Stato': 0.08695652173913043, 'word_1_fondatore': 0.043478260869565216, 'word_1_in': 0.043478260869565216, 'word_1_affondatore': 0.043478260869565216, 'word_1_Unione': 0.043478260869565216, 'word_1_europea': 0.043478260869565216, 'word_1_!': 0.043478260869565216, 'word_1_<URL>': 0.043478260869565216, 'word_2_Mario_Monti': 0.043478260869565216, 'word_2_Monti_:': 0.043478260869565216, \"word_2_:_c'\": 0.043478260869565216, \"word_2_c'_è\": 0.043478260869565216, 'word_2_è_il': 0.043478260869565216, 'word_2_il_rischio...': 0.043478260869565216, 'word_2_rischio..._di': 0.043478260869565216, 'word_2_di_trasformare': 0.043478260869565216, \"word_2_trasformare_l'\": 0.043478260869565216, \"word_2_l'_Italia\": 0.043478260869565216, 'word_2_Italia_da': 0.043478260869565216, 'word_2_da_Stato': 0.043478260869565216, 'word_2_Stato_fondatore': 0.043478260869565216, 'word_2_fondatore_in': 0.043478260869565216, 'word_2_in_Stato': 0.043478260869565216, 'word_2_Stato_affondatore': 0.043478260869565216, 'word_2_affondatore_di': 0.043478260869565216, \"word_2_di_l'\": 0.043478260869565216, \"word_2_l'_Unione\": 0.043478260869565216, 'word_2_Unione_europea': 0.043478260869565216, 'word_2_europea_!': 0.043478260869565216, 'word_2_!_<URL>': 0.043478260869565216, 'char_1_M': 0.016, 'char_1_a': 0.096, 'char_1_r': 0.064, 'char_1_i': 0.08, 'char_1_o': 0.096, 'char_1_ ': 0.176, 'char_1_n': 0.048, 'char_1_t': 0.072, 'char_1_:': 0.008, 'char_1_c': 0.016, \"char_1_'\": 0.024, 'char_1_è': 0.008, 'char_1_l': 0.032, 'char_1_s': 0.016, 'char_1_h': 0.008, 'char_1_.': 0.024, 'char_1_d': 0.04, 'char_1_f': 0.032, 'char_1_m': 0.008, 'char_1_e': 0.048, 'char_1_I': 0.008, 'char_1_S': 0.016, 'char_1_U': 0.016, 'char_1_u': 0.008, 'char_1_p': 0.008, 'char_1_!': 0.008, 'char_1_<': 0.008, 'char_1_R': 0.008, 'char_1_L': 0.008, 'char_1_>': 0.008, 'char_2_M_a': 0.008, 'char_2_a_r': 0.016, 'char_2_r_i': 0.016, 'char_2_i_o': 0.024, 'char_2_o_ ': 0.024, 'char_2_ _M': 0.008, 'char_2_M_o': 0.008, 'char_2_o_n': 0.032, 'char_2_n_t': 0.008, 'char_2_t_i': 0.008, 'char_2_i_ ': 0.024, 'char_2_ _:': 0.008, 'char_2_:_ ': 0.008, 'char_2_ _c': 0.008, \"char_2_c_'\": 0.008, \"char_2_'_ \": 0.024, 'char_2_ _è': 0.008, 'char_2_è_ ': 0.008, 'char_2_ _i': 0.016, 'char_2_i_l': 0.008, 'char_2_l_ ': 0.008, 'char_2_ _r': 0.008, 'char_2_i_s': 0.008, 'char_2_s_c': 0.008, 'char_2_c_h': 0.008, 'char_2_h_i': 0.008, 'char_2_o_.': 0.008, 'char_2_._.': 0.016, 'char_2_._ ': 0.008, 'char_2_ _d': 0.024, 'char_2_d_i': 0.016, 'char_2_ _t': 0.008, 'char_2_t_r': 0.008, 'char_2_r_a': 0.008, 'char_2_a_s': 0.008, 'char_2_s_f': 0.008, 'char_2_f_o': 0.024, 'char_2_o_r': 0.024, 'char_2_r_m': 0.008, 'char_2_m_a': 0.008, 'char_2_r_e': 0.024, 'char_2_e_ ': 0.032, 'char_2_ _l': 0.016, \"char_2_l_'\": 0.016, 'char_2_ _I': 0.008, 'char_2_I_t': 0.008, 'char_2_t_a': 0.024, 'char_2_a_l': 0.008, 'char_2_l_i': 0.008, 'char_2_i_a': 0.008, 'char_2_a_ ': 0.024, 'char_2_d_a': 0.024, 'char_2_ _S': 0.016, 'char_2_S_t': 0.016, 'char_2_a_t': 0.032, 'char_2_t_o': 0.032, 'char_2_ _f': 0.008, 'char_2_n_d': 0.016, 'char_2_i_n': 0.008, 'char_2_n_ ': 0.008, 'char_2_ _a': 0.008, 'char_2_a_f': 0.008, 'char_2_f_f': 0.008, 'char_2_ _U': 0.008, 'char_2_U_n': 0.008, 'char_2_n_i': 0.008, 'char_2_n_e': 0.008, 'char_2_ _e': 0.008, 'char_2_e_u': 0.008, 'char_2_u_r': 0.008, 'char_2_r_o': 0.008, 'char_2_o_p': 0.008, 'char_2_p_e': 0.008, 'char_2_e_a': 0.008, 'char_2_ _!': 0.008, 'char_2_!_ ': 0.008, 'char_2_ _<': 0.008, 'char_2_<_U': 0.008, 'char_2_U_R': 0.008, 'char_2_R_L': 0.008, 'char_2_L_>': 0.008}\n"
     ]
    }
   ],
   "source": [
    "#funzione che unisce per ogni post i diversi tipi di n-grammi\n",
    "def get_features(dataset, info_types):\n",
    "    all_features = []\n",
    "    for post in dataset: \n",
    "        complete_dict = dict()\n",
    "        for info in info_types:\n",
    "            info_dict = count_ngrams(post, info[0], info[1], info[2])\n",
    "            complete_dict = complete_dict | info_dict\n",
    "        all_features.append(complete_dict)\n",
    "    return all_features\n",
    "\n",
    "#per cambiare tipo di n-grammi cambiare questi parametri\n",
    "infos = [['word', 1, False], ['word', 2, False], ['word', 1, True], ['word', 2, True]]\n",
    "info_description = f'unigrammi parole; bigrammi parole; unigrammi caratteri; bigrammi caratteri;'\n",
    "\n",
    "#si crea la lista di occorrenze di n-grammi per training e test\n",
    "tr_features = get_features(annotation_tr, infos)\n",
    "ts_features = get_features(annotation_ts, infos)\n",
    "\n",
    "print(tr_features[1])\n",
    "    \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ridurre la dimensionalità della nostra matrice, eliminiamo gli n-grammi che occorrono in un numero di documenti sotto una soglia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che estrae la lista di feature presenti all'interno del dataset\n",
    "def get_feature_list(feature_set):\n",
    "    feature_list = []\n",
    "    for post in feature_set:\n",
    "        for feature in post:\n",
    "            if feature not in feature_list:\n",
    "                feature_list.append(feature)\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = get_feature_list(tr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di features prima del filtro: 64468\n",
      "Numero di features dopo il filtro: 7534\n"
     ]
    }
   ],
   "source": [
    "#funzione che ritorna True se le occorrenze sono al di sopra di un valore soglia, e False altrimenti\n",
    "def is_common(feature, feature_set, min_occurrences):\n",
    "    count = 0\n",
    "    for post in feature_set:\n",
    "        if feature in post:\n",
    "            count += 1\n",
    "    if count < min_occurrences:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#passiamo la funzione is_common come parametro di filter, così facendo si ottiene una nuova lista di features con solo le features più comuni  \n",
    "filtered_features = list(filter(lambda x: is_common(x, tr_features, 3), all_features))\n",
    "print(f'Numero di features prima del filtro: {len(all_features)}')\n",
    "print(f'Numero di features dopo il filtro: {len(filtered_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di features per sample non filtrato: 135\n",
      "Numero di features in un sample filtrato: 125\n"
     ]
    }
   ],
   "source": [
    "#funzione che filtra il dataset mantenendo solo gli n-grammi che si trovano nella lista features_to_keep\n",
    "def filter_dataset(dataset, features_tokeep):\n",
    "    for post in dataset:\n",
    "        post_features = list(post.keys())\n",
    "        for feature in post_features:\n",
    "            if feature not in features_tokeep:\n",
    "                post.pop(feature)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "print(f'Numero di features per sample non filtrato: {len(tr_features[10])}')\n",
    "tr_features = filter_dataset(tr_features, filtered_features)\n",
    "print(f'Numero di features in un sample filtrato: {len(tr_features[10])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "\n",
    "#si trasformano i dizionari con le occorrenze degli n-grammi in vettori di features\n",
    "vectorizer = DictVectorizer()\n",
    "tr_set = vectorizer.fit_transform(tr_features)\n",
    "#si scalano i valori\n",
    "scaler = MaxAbsScaler()\n",
    "tr_set = scaler.fit_transform(tr_set)\n",
    "#si \n",
    "tr_labels = create_labels(\"training\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training e Validation con diversi tipi di informazione\n",
    "\n",
    "Si valutano le diverse tipologie e combinazioni di n-grammi, ognuna con un processo di 5-fold validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Fold n.1 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.6846733668341709\n",
      "Accuracy della baseline: 0.5062814070351759\n",
      "-------------------------Fold n.2 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.6959798994974874\n",
      "Accuracy della baseline: 0.45226130653266333\n",
      "-------------------------Fold n.3 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.6981132075471698\n",
      "Accuracy della baseline: 0.5031446540880503\n",
      "-------------------------Fold n.4 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.70062893081761\n",
      "Accuracy della baseline: 0.47924528301886793\n",
      "-------------------------Fold n.5 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.6918238993710691\n",
      "Accuracy della baseline: 0.5069182389937107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('results.txt', 'a') as file:\\n    file.write(f'{info_description}\\n')\\n    for i in range(len(all_acc)):\\n        file.write(f'Risultati Fold {i+1} -->  Accuracy modello: {all_acc[i]} | Accuracy baseline: {all_dummy_acc[i]}  \\n')\\n    file.write(f'Media: {avg(all_acc)}')\\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dividiamo per ogni fold in train e validation set\n",
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "folds = list(splitter.split(tr_set))\n",
    "\n",
    "tr_labels = np.asarray(tr_labels)\n",
    "i=1\n",
    "real_lbls = []\n",
    "predicted = []\n",
    "all_acc = []\n",
    "all_dummy_acc = []\n",
    "\n",
    "#per ogni fold definita\n",
    "for fold in folds:\n",
    "    print(f'-------------------------Fold n.{i} just started!-------------------------')\n",
    "    #si creano i set per ogni fold, training e test\n",
    "    train_index = fold[0]\n",
    "    test_index = fold[1]\n",
    "    #train set\n",
    "    x_train = tr_set[train_index]\n",
    "    y_train = tr_labels[train_index]\n",
    "    #test set\n",
    "    x_test = tr_set[test_index]\n",
    "    y_test = tr_labels[test_index]\n",
    "    #inizio del training\n",
    "    ksvc = LinearSVC(dual=False)\n",
    "    ksvc.fit(x_train, y_train)\n",
    "    #predictions\n",
    "    pred = ksvc.predict(x_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    #usiamo un Dummy Classifier come Baseline\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(x_train, y_train)\n",
    "    dummy_acc = dummy.score(x_test, y_test)\n",
    "    real_lbls+=y_test.tolist()\n",
    "    predicted+=pred.tolist()\n",
    "    all_acc.append(acc)\n",
    "    all_dummy_acc.append(dummy_acc)\n",
    "    print(\"---> test: \")\n",
    "    print(f\"Accuracy del modello: {acc}\\nAccuracy della baseline: {dummy_acc}\")\n",
    "    i+=1\n",
    "\n",
    "\n",
    "def avg(x):\n",
    "    return sum(x)/len(x)\n",
    "\n",
    "'''\n",
    "with open('results.txt', 'a') as file:\n",
    "    file.write(f'{info_description}\\n')\n",
    "    for i in range(len(all_acc)):\n",
    "        file.write(f'Risultati Fold {i+1} -->  Accuracy modello: {all_acc[i]} | Accuracy baseline: {all_dummy_acc[i]}  \\n')\n",
    "    file.write(f'Media: {avg(all_acc)}')\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Una volta ottenuta la configurazione di input migliore (con accuratezza più alta), si procede a testare il modello con l'input che ha avuto le migliori prestazioni. In questo caso si tratta di unigrammi e bigrammi di caratteri e unigrammi e bigrammi di parole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si trasformano i dizionari con le occorrenze di n-grammi del test in vettori \n",
    "ts_set = vectorizer.transform(ts_features)\n",
    "ts_set = scaler.transform(ts_set)\n",
    "ts_labels = create_labels(\"test\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.59      0.64       437\n",
      "           1       0.64      0.72      0.68       435\n",
      "\n",
      "    accuracy                           0.66       872\n",
      "   macro avg       0.66      0.66      0.66       872\n",
      "weighted avg       0.66      0.66      0.66       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#si fanno le prediction del modello sul test set\n",
    "test_preds = ksvc.predict(ts_set)\n",
    "print(classification_report(ts_labels, test_preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x26bf4ef7310>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(ts_labels, test_preds, cmap=\"YlGnBu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
