{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. CLASSIFICATORE LINEARE SVM CON INPUT DI N-GRAMMI\n",
    "\n",
    "Classificatore basato su  SVM che prende in input una matrice di features basata su n-grammi di 3 tipi:\n",
    "1. Caratteri\n",
    "2. Token\n",
    "3. Part of Speech\n",
    "\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing dei dati\n",
    "\n",
    "Dobbiamo ottenere un vettore di features, basato sulle occorrenze di n-grammi all'interno delle frasi, per ciascun post. Come prima cosa si crea si per training che per test un set formato da liste di dizionari. I dizionari riportano per ogni token 3 campi che corrispondono alla parola, la forma lemmatizzata e la parte del discorso. Infine contiamo all'interno dei post le occorrenze degli n-grammi. Una volta ottenuti tutti gli n-grammi possiamo creare la matrice di occorrenze. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creiamo un dizionario che abbia 3 campi: word, lemma e part of speech(pos)\n",
    "def create_set(type):\n",
    "    annotated_posts = []\n",
    "    for doc in os.listdir(\"../data/UD_annotation\"):\n",
    "        if type in doc: \n",
    "            doc_tokens = []\n",
    "            doc_path = \"../data/UD_annotation/\" + doc\n",
    "            for line in open(doc_path, \"r\", encoding=\"utf-8\"):\n",
    "                splitted = line.strip().split(\"\\t\")\n",
    "                if splitted[0].isdigit() and \"-\" not in splitted[0]:\n",
    "                    word=splitted[1]\n",
    "                    lemma=splitted[2]\n",
    "                    pos=splitted[3]\n",
    "                    new_token = {'word': word, 'lemma': lemma, 'pos': pos}\n",
    "                    doc_tokens.append(new_token)\n",
    "            annotated_posts.append(doc_tokens)\n",
    "    return annotated_posts\n",
    "\n",
    "annotation_tr = create_set(\"training\")\n",
    "annotation_ts = create_set(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che estrae le labels dal nome del file\n",
    "def create_labels(type):\n",
    "    labels_irony = []\n",
    "    labels_sarcasm = []\n",
    "    for doc in os.listdir(\"../data/UD_annotation\"):\n",
    "        if type in doc: \n",
    "            splitted = doc.split(\"#\")\n",
    "            irony = splitted[2]\n",
    "            sarcasm = splitted[3]\n",
    "            labels_irony.append(irony)\n",
    "            labels_sarcasm.append(sarcasm)\n",
    "    return labels_irony, labels_sarcasm\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 3977\n",
      "Test: 872\n"
     ]
    }
   ],
   "source": [
    "#contiamo il numero di post(sample) per training e test\n",
    "print(f'Training: {len(annotation_tr)}')\n",
    "print(f'Test: {len(annotation_ts)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word_2_#la7_ma': 0.05555555555555555, 'word_2_ma_perche': 0.05555555555555555, \"word_2_perche_'\": 0.05555555555555555, \"word_2_'_Mario\": 0.05555555555555555, 'word_2_Mario_Monti': 0.05555555555555555, 'word_2_Monti_non': 0.05555555555555555, 'word_2_non_fa': 0.05555555555555555, 'word_2_fa_il': 0.05555555555555555, 'word_2_il_premier': 0.05555555555555555, 'word_2_premier_?': 0.05555555555555555, 'word_2_?_Che': 0.05555555555555555, 'word_2_Che_persona': 0.05555555555555555, 'word_2_persona_competente': 0.05555555555555555, 'word_2_competente_e': 0.05555555555555555, 'word_2_e_per': 0.05555555555555555, 'word_2_per_bene': 0.05555555555555555, 'word_2_bene_!': 0.05555555555555555}\n"
     ]
    }
   ],
   "source": [
    "#funzione che conta le occorrenze degli ngrammi all'interno di un post\n",
    "def count_ngrams(post, ft_type, n, char=False):\n",
    "    all_ngrams = {}\n",
    "    allwords = []\n",
    "    if not char:\n",
    "        for word in post:\n",
    "            allwords.append(word[ft_type])\n",
    "        post_length = len(allwords)\n",
    "    else:\n",
    "        for word in post:\n",
    "            allwords.append(word['word'])\n",
    "        allwords = \" \".join(allwords)\n",
    "        post_length = len(allwords)-1\n",
    "    for i in range(len(allwords)-(n-1)):\n",
    "        new_ngram = allwords[i:i+n]\n",
    "        if not char:\n",
    "            ngram_id = f'{ft_type}_{n}_'+'_'.join(new_ngram)\n",
    "        else:\n",
    "            ngram_id = f'char_{n}_'+'_'.join(new_ngram)\n",
    "        if ngram_id not in all_ngrams:\n",
    "            all_ngrams[ngram_id] = 1\n",
    "        else:\n",
    "            all_ngrams[ngram_id]+=1\n",
    "    #normalizzare in base alla post_length\n",
    "    for ngram in all_ngrams:\n",
    "        all_ngrams[ngram] = all_ngrams[ngram]/post_length\n",
    "    return all_ngrams\n",
    "\n",
    "print(count_ngrams(annotation_tr[2], \"word\", 2, False))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uniamo per ogni tipo di informazione che vogliamo i relativi dizionari, così da avere un dizionario denso di informazioni. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word_1_Mario': 0.043478260869565216, 'word_1_Monti': 0.043478260869565216, 'word_1_:': 0.043478260869565216, \"word_1_c'\": 0.043478260869565216, 'word_1_è': 0.043478260869565216, 'word_1_il': 0.043478260869565216, 'word_1_rischio...': 0.043478260869565216, 'word_1_di': 0.08695652173913043, 'word_1_trasformare': 0.043478260869565216, \"word_1_l'\": 0.08695652173913043, 'word_1_Italia': 0.043478260869565216, 'word_1_da': 0.043478260869565216, 'word_1_Stato': 0.08695652173913043, 'word_1_fondatore': 0.043478260869565216, 'word_1_in': 0.043478260869565216, 'word_1_affondatore': 0.043478260869565216, 'word_1_Unione': 0.043478260869565216, 'word_1_europea': 0.043478260869565216, 'word_1_!': 0.043478260869565216, 'word_1_<URL>': 0.043478260869565216, 'word_2_Mario_Monti': 0.043478260869565216, 'word_2_Monti_:': 0.043478260869565216, \"word_2_:_c'\": 0.043478260869565216, \"word_2_c'_è\": 0.043478260869565216, 'word_2_è_il': 0.043478260869565216, 'word_2_il_rischio...': 0.043478260869565216, 'word_2_rischio..._di': 0.043478260869565216, 'word_2_di_trasformare': 0.043478260869565216, \"word_2_trasformare_l'\": 0.043478260869565216, \"word_2_l'_Italia\": 0.043478260869565216, 'word_2_Italia_da': 0.043478260869565216, 'word_2_da_Stato': 0.043478260869565216, 'word_2_Stato_fondatore': 0.043478260869565216, 'word_2_fondatore_in': 0.043478260869565216, 'word_2_in_Stato': 0.043478260869565216, 'word_2_Stato_affondatore': 0.043478260869565216, 'word_2_affondatore_di': 0.043478260869565216, \"word_2_di_l'\": 0.043478260869565216, \"word_2_l'_Unione\": 0.043478260869565216, 'word_2_Unione_europea': 0.043478260869565216, 'word_2_europea_!': 0.043478260869565216, 'word_2_!_<URL>': 0.043478260869565216, 'char_1_M': 0.016, 'char_1_a': 0.096, 'char_1_r': 0.064, 'char_1_i': 0.08, 'char_1_o': 0.096, 'char_1_ ': 0.176, 'char_1_n': 0.048, 'char_1_t': 0.072, 'char_1_:': 0.008, 'char_1_c': 0.016, \"char_1_'\": 0.024, 'char_1_è': 0.008, 'char_1_l': 0.032, 'char_1_s': 0.016, 'char_1_h': 0.008, 'char_1_.': 0.024, 'char_1_d': 0.04, 'char_1_f': 0.032, 'char_1_m': 0.008, 'char_1_e': 0.048, 'char_1_I': 0.008, 'char_1_S': 0.016, 'char_1_U': 0.016, 'char_1_u': 0.008, 'char_1_p': 0.008, 'char_1_!': 0.008, 'char_1_<': 0.008, 'char_1_R': 0.008, 'char_1_L': 0.008, 'char_1_>': 0.008, 'char_2_M_a': 0.008, 'char_2_a_r': 0.016, 'char_2_r_i': 0.016, 'char_2_i_o': 0.024, 'char_2_o_ ': 0.024, 'char_2_ _M': 0.008, 'char_2_M_o': 0.008, 'char_2_o_n': 0.032, 'char_2_n_t': 0.008, 'char_2_t_i': 0.008, 'char_2_i_ ': 0.024, 'char_2_ _:': 0.008, 'char_2_:_ ': 0.008, 'char_2_ _c': 0.008, \"char_2_c_'\": 0.008, \"char_2_'_ \": 0.024, 'char_2_ _è': 0.008, 'char_2_è_ ': 0.008, 'char_2_ _i': 0.016, 'char_2_i_l': 0.008, 'char_2_l_ ': 0.008, 'char_2_ _r': 0.008, 'char_2_i_s': 0.008, 'char_2_s_c': 0.008, 'char_2_c_h': 0.008, 'char_2_h_i': 0.008, 'char_2_o_.': 0.008, 'char_2_._.': 0.016, 'char_2_._ ': 0.008, 'char_2_ _d': 0.024, 'char_2_d_i': 0.016, 'char_2_ _t': 0.008, 'char_2_t_r': 0.008, 'char_2_r_a': 0.008, 'char_2_a_s': 0.008, 'char_2_s_f': 0.008, 'char_2_f_o': 0.024, 'char_2_o_r': 0.024, 'char_2_r_m': 0.008, 'char_2_m_a': 0.008, 'char_2_r_e': 0.024, 'char_2_e_ ': 0.032, 'char_2_ _l': 0.016, \"char_2_l_'\": 0.016, 'char_2_ _I': 0.008, 'char_2_I_t': 0.008, 'char_2_t_a': 0.024, 'char_2_a_l': 0.008, 'char_2_l_i': 0.008, 'char_2_i_a': 0.008, 'char_2_a_ ': 0.024, 'char_2_d_a': 0.024, 'char_2_ _S': 0.016, 'char_2_S_t': 0.016, 'char_2_a_t': 0.032, 'char_2_t_o': 0.032, 'char_2_ _f': 0.008, 'char_2_n_d': 0.016, 'char_2_i_n': 0.008, 'char_2_n_ ': 0.008, 'char_2_ _a': 0.008, 'char_2_a_f': 0.008, 'char_2_f_f': 0.008, 'char_2_ _U': 0.008, 'char_2_U_n': 0.008, 'char_2_n_i': 0.008, 'char_2_n_e': 0.008, 'char_2_ _e': 0.008, 'char_2_e_u': 0.008, 'char_2_u_r': 0.008, 'char_2_r_o': 0.008, 'char_2_o_p': 0.008, 'char_2_p_e': 0.008, 'char_2_e_a': 0.008, 'char_2_ _!': 0.008, 'char_2_!_ ': 0.008, 'char_2_ _<': 0.008, 'char_2_<_U': 0.008, 'char_2_U_R': 0.008, 'char_2_R_L': 0.008, 'char_2_L_>': 0.008}\n"
     ]
    }
   ],
   "source": [
    "#funzione che unisce per ogni post i diversi tipi di n-grammi\n",
    "def get_features(dataset, info_types):\n",
    "    all_features = []\n",
    "    for post in dataset: \n",
    "        complete_dict = dict()\n",
    "        for info in info_types:\n",
    "            info_dict = count_ngrams(post, info[0], info[1], info[2])\n",
    "            complete_dict = complete_dict | info_dict\n",
    "        all_features.append(complete_dict)\n",
    "    return all_features\n",
    "\n",
    "#per cambiare tipo di info cambiare questi parametri\n",
    "infos = [['word', 1, False], ['word', 2, False], ['word', 1, True], ['word', 2, True]]\n",
    "info_description = f'unigrammi parole; bigrammi parole; unigrammi caratteri; bigrammi caratteri;'\n",
    "\n",
    "tr_features = get_features(annotation_tr, infos)\n",
    "ts_features = get_features(annotation_ts, infos)\n",
    "\n",
    "print(tr_features[1])\n",
    "    \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ridurre la dimensionalità della nostra matrice, eliminiamo gli n-grammi che occorrono in un numero di documenti sotto una soglia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che estrae la lista di feature presenti all'interno del dataset\n",
    "def get_feature_list(feature_set):\n",
    "    feature_list = []\n",
    "    for post in feature_set:\n",
    "        for feature in post:\n",
    "            if feature not in feature_list:\n",
    "                feature_list.append(feature)\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = get_feature_list(tr_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di features prima del filtro: 64468\n",
      "Numero di features dopo il filtro: 7534\n"
     ]
    }
   ],
   "source": [
    "#funzione che ritorna True se le occorrenze sono al di sopra di un valore soglia, e False altrimenti\n",
    "def is_common(feature, feature_set, min_occurrences):\n",
    "    count = 0\n",
    "    for post in feature_set:\n",
    "        if feature in post:\n",
    "            count += 1\n",
    "    if count < min_occurrences:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#passiamo la funzione is_common come parametro di filter, così facendo si ottiene una nuova lista di features con solo le features più comuni  \n",
    "filtered_features = list(filter(lambda x: is_common(x, tr_features, 3), all_features))\n",
    "print(f'Numero di features prima del filtro: {len(all_features)}')\n",
    "print(f'Numero di features dopo il filtro: {len(filtered_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di features per sample non filtrato: 135\n",
      "Numero di features in un sample filtrato: 125\n"
     ]
    }
   ],
   "source": [
    "def filter_dataset(dataset, features_tokeep):\n",
    "    for post in dataset:\n",
    "        post_features = list(post.keys())\n",
    "        for feature in post_features:\n",
    "            if feature not in features_tokeep:\n",
    "                post.pop(feature)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "print(f'Numero di features per sample non filtrato: {len(tr_features[10])}')\n",
    "tr_features = filter_dataset(tr_features, filtered_features)\n",
    "print(f'Numero di features in un sample filtrato: {len(tr_features[10])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vectorizer = DictVectorizer()\n",
    "tr_set = vectorizer.fit_transform(tr_features)\n",
    "scaler = MaxAbsScaler()\n",
    "tr_set = scaler.fit_transform(tr_set)\n",
    "tr_labels_irony, tr_labels_sarcasm = create_labels(\"training\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(max_iter=10000)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(dual=True, max_iter=10000)\n",
    "svc.fit(tr_set, tr_labels_irony)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation con diversi tipi di informazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Fold n.1 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.6846733668341709\n",
      "Accuracy della baseline: 0.5062814070351759\n",
      "-------------------------Fold n.2 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.6959798994974874\n",
      "Accuracy della baseline: 0.45226130653266333\n",
      "-------------------------Fold n.3 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.6981132075471698\n",
      "Accuracy della baseline: 0.5031446540880503\n",
      "-------------------------Fold n.4 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.70062893081761\n",
      "Accuracy della baseline: 0.47924528301886793\n",
      "-------------------------Fold n.5 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.6918238993710691\n",
      "Accuracy della baseline: 0.5069182389937107\n"
     ]
    }
   ],
   "source": [
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "folds = list(splitter.split(tr_set))\n",
    "\n",
    "tr_labels = np.asarray(tr_labels_irony)\n",
    "i=1\n",
    "real_lbls = []\n",
    "predicted = []\n",
    "all_acc = []\n",
    "all_dummy_acc = []\n",
    "\n",
    "for fold in folds:\n",
    "    print(f'-------------------------Fold n.{i} just started!-------------------------')\n",
    "    #si creano i set per ogni fold, training e test\n",
    "    train_index = fold[0]\n",
    "    test_index = fold[1]\n",
    "    #train set\n",
    "    x_train = tr_set[train_index]\n",
    "    y_train = tr_labels[train_index]\n",
    "    #test set\n",
    "    x_test = tr_set[test_index]\n",
    "    y_test = tr_labels[test_index]\n",
    "    #inizio del training\n",
    "    ksvc = LinearSVC(dual=False)\n",
    "    ksvc.fit(x_train, y_train)\n",
    "    #predictions\n",
    "    pred = ksvc.predict(x_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    #usiamo un Dummy Classifier come Baseline\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(x_train, y_train)\n",
    "    dummy_acc = dummy.score(x_test, y_test)\n",
    "    real_lbls+=y_test.tolist()\n",
    "    predicted+=pred.tolist()\n",
    "    all_acc.append(acc)\n",
    "    all_dummy_acc.append(dummy_acc)\n",
    "    print(\"---> test: \")\n",
    "    print(f\"Accuracy del modello: {acc}\\nAccuracy della baseline: {dummy_acc}\")\n",
    "    i+=1\n",
    "\n",
    "\n",
    "def avg(x):\n",
    "    return sum(x)/len(x)\n",
    "\n",
    "'''\n",
    "with open('results.txt', 'a') as file:\n",
    "    file.write(f'{info_description}\\n')\n",
    "    for i in range(len(all_acc)):\n",
    "        file.write(f'Risultati Fold {i+1} -->  Accuracy modello: {all_acc[i]} | Accuracy baseline: {all_dummy_acc[i]}  \\n')\n",
    "    file.write(f'Media: {avg(all_acc)}')\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Una volta ottenuta la configurazione di input migliore (con accuratezza più alta), si procede a testare il modello con l'input che ha avuto le migliori prestazioni. In questo caso si tratta di unigrammi e bigrammi di caratteri e unigrammi e bigrammi di parole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ts_set = filter_dataset(ts_features, filtered_features)\n",
    "ts_set = vectorizer.transform(ts_features)\n",
    "ts_set = scaler.transform(ts_set)\n",
    "ts_labels_irony, ts_labels_sarcasm = create_labels(\"test\")\n",
    "ts_labels = ts_labels_irony\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.62      0.66       437\n",
      "           1       0.66      0.72      0.68       435\n",
      "\n",
      "    accuracy                           0.67       872\n",
      "   macro avg       0.67      0.67      0.67       872\n",
      "weighted avg       0.67      0.67      0.67       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = svc.predict(ts_set)\n",
    "print(classification_report(ts_labels, test_preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x1778a3b9390>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(ts_labels, test_preds, cmap=\"YlGnBu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
