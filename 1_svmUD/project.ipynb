{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CLASSIFICATORE SVM CON INPUT DI PROFILING UD: \n",
    "\n",
    "classificatore basato su SVM lineari che prende in input una rappresentazione del testo basata solo su informazioni linguistiche non lessicali estratte utilizzando il sistema Profiling-UD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing per Profiling UD\n",
    "\n",
    "Per ottenere le features da Profiling UD è necessario fare del pre-processing sul dataset per fare in modo da avere per ogni sample del dataset un file txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vediamo un po' cos'abbiamo come training e test set\n",
    "training_set = pd.read_csv(\"../data/training_ironita2018_anon_REV_.csv\", sep=\";\")\n",
    "test_set = pd.read_csv(\"../data/test_gold_ironita2018_anon_REV_.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>irony</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>811156813181841408</td>\n",
       "      <td>Zurigo, trovato morto il presunto autore della...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>811183087350595584</td>\n",
       "      <td>Zurigo, trovato morto il presunto autore della...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>826380632376881152</td>\n",
       "      <td>Zingari..i soliti \"MERDOSI\"..#cacciamolivia Ro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>844871171350802432</td>\n",
       "      <td>Zingari di merda,tutti al muro...bastardi Spar...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>509712824361570304</td>\n",
       "      <td>zero notizie decreto #tfaordinario II ciclo ze...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TW-BS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  811156813181841408  Zurigo, trovato morto il presunto autore della...   \n",
       "1  811183087350595584  Zurigo, trovato morto il presunto autore della...   \n",
       "2  826380632376881152  Zingari..i soliti \"MERDOSI\"..#cacciamolivia Ro...   \n",
       "3  844871171350802432  Zingari di merda,tutti al muro...bastardi Spar...   \n",
       "4  509712824361570304  zero notizie decreto #tfaordinario II ciclo ze...   \n",
       "\n",
       "   irony  sarcasm  topic  \n",
       "0      0        0    HSC  \n",
       "1      0        0    HSC  \n",
       "2      0        0    HSC  \n",
       "3      0        0    HSC  \n",
       "4      1        0  TW-BS  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>irony</th>\n",
       "      <th>sarcasm</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>595524450503815168</td>\n",
       "      <td>-Prendere i libri in copisteria-Fare la spesa-...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>TWITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>578468106504433665</td>\n",
       "      <td>...comunque con una crociera Costa se non ti a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>HSC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>577791521174466560</td>\n",
       "      <td>“&lt;MENTION_1&gt; Ogni ragazza: \\\"non sono una raga...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>TWITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>507464919303069697</td>\n",
       "      <td>“La buona scuola”? Fa gli errori di grammatica...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TW-BS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>839896135619727362</td>\n",
       "      <td>“Vi hanno sfrattato? Andate al campo rom in un...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>HSC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                               text  \\\n",
       "0  595524450503815168  -Prendere i libri in copisteria-Fare la spesa-...   \n",
       "1  578468106504433665  ...comunque con una crociera Costa se non ti a...   \n",
       "2  577791521174466560  “<MENTION_1> Ogni ragazza: \\\"non sono una raga...   \n",
       "3  507464919303069697  “La buona scuola”? Fa gli errori di grammatica...   \n",
       "4  839896135619727362  “Vi hanno sfrattato? Andate al campo rom in un...   \n",
       "\n",
       "   irony  sarcasm  topic  \n",
       "0      1        0  TWITA  \n",
       "1      1        0    HSC  \n",
       "2      1        1  TWITA  \n",
       "3      0        0  TW-BS  \n",
       "4      0        0    HSC  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, set_type):\n",
    "    for index,row in df.iterrows():\n",
    "        filename = f'profiling_input/{set_type}#{row[\"id\"]}#{row[\"irony\"]}#{row[\"sarcasm\"]}#{row[\"topic\"]}.txt'\n",
    "        with open(filename, 'w', encoding='utf-8') as single_file:\n",
    "            single_file.write(row[\"text\"]) \n",
    "\n",
    "transform(training_set, \"training\")\n",
    "transform(test_set, \"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta ottenuti i singoli documenti corrispondenti ai singoli sample del dataset, questi vengono passati a profiling UD.\n",
    "Questo restituirà un nuovo dataset (formato csv) con un insieme di features basate sulla profilazione dei testi (x es. lunghezza delle frasi ecc.).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing per modello SVM \n",
    "\n",
    "In questa sezione viene caricato il dataset restituito da profiling UD e vengono eseguiti una serie di procedimenti per la standardizzazione dei dati, così da poter poi essere passati al modello SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>tokens_per_sent</th>\n",
       "      <th>char_per_tok</th>\n",
       "      <th>upos_dist_ADJ</th>\n",
       "      <th>upos_dist_ADP</th>\n",
       "      <th>upos_dist_ADV</th>\n",
       "      <th>upos_dist_AUX</th>\n",
       "      <th>upos_dist_CCONJ</th>\n",
       "      <th>...</th>\n",
       "      <th>principal_proposition_dist</th>\n",
       "      <th>subordinate_proposition_dist</th>\n",
       "      <th>subordinate_post</th>\n",
       "      <th>subordinate_pre</th>\n",
       "      <th>avg_subordinate_chain_len</th>\n",
       "      <th>subordinate_dist_1</th>\n",
       "      <th>subordinate_dist_2</th>\n",
       "      <th>subordinate_dist_3</th>\n",
       "      <th>subordinate_dist_4</th>\n",
       "      <th>subordinate_dist_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training#799528852410265600#1#1#HSC.conllu</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training#808400282107445250#0#0#HSC.conllu</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training#553992006671024129#1#1#HSC.conllu</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training#531752278152462336#1#0#TW-BS.conllu</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>training#507259632075542528#1#1#TW-BS.conllu</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.680000</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>19.230769</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 134 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Filename  n_sentences  n_tokens  \\\n",
       "0    training#799528852410265600#1#1#HSC.conllu            1        19   \n",
       "1    training#808400282107445250#0#0#HSC.conllu            2        15   \n",
       "2    training#553992006671024129#1#1#HSC.conllu            1        14   \n",
       "3  training#531752278152462336#1#0#TW-BS.conllu            2        12   \n",
       "4  training#507259632075542528#1#1#TW-BS.conllu            2        26   \n",
       "\n",
       "   tokens_per_sent  char_per_tok  upos_dist_ADJ  upos_dist_ADP  upos_dist_ADV  \\\n",
       "0             19.0      5.250000      10.526316       5.263158       0.000000   \n",
       "1              7.5      7.230769       0.000000      13.333333       0.000000   \n",
       "2             14.0      4.571429      21.428571      14.285714       0.000000   \n",
       "3              6.0      6.181818       0.000000       8.333333       0.000000   \n",
       "4             13.0      4.680000       7.692308      19.230769       7.692308   \n",
       "\n",
       "   upos_dist_AUX  upos_dist_CCONJ  ...  principal_proposition_dist  \\\n",
       "0       0.000000         5.263158  ...                  100.000000   \n",
       "1       0.000000         0.000000  ...                    0.000000   \n",
       "2       7.142857         7.142857  ...                  100.000000   \n",
       "3       0.000000         8.333333  ...                  100.000000   \n",
       "4       3.846154         0.000000  ...                   66.666667   \n",
       "\n",
       "   subordinate_proposition_dist  subordinate_post  subordinate_pre  \\\n",
       "0                      0.000000               0.0              0.0   \n",
       "1                      0.000000               0.0              0.0   \n",
       "2                      0.000000               0.0              0.0   \n",
       "3                      0.000000               0.0              0.0   \n",
       "4                     33.333333             100.0              0.0   \n",
       "\n",
       "   avg_subordinate_chain_len  subordinate_dist_1  subordinate_dist_2  \\\n",
       "0                        0.0                 0.0                 0.0   \n",
       "1                        0.0                 0.0                 0.0   \n",
       "2                        0.0                 0.0                 0.0   \n",
       "3                        0.0                 0.0                 0.0   \n",
       "4                        1.0               100.0                 0.0   \n",
       "\n",
       "   subordinate_dist_3  subordinate_dist_4  subordinate_dist_5  \n",
       "0                 0.0                 0.0                 0.0  \n",
       "1                 0.0                 0.0                 0.0  \n",
       "2                 0.0                 0.0                 0.0  \n",
       "3                 0.0                 0.0                 0.0  \n",
       "4                 0.0                 0.0                 0.0  \n",
       "\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UD_dataset = pd.read_csv(\"profiling_output/7075.csv\", sep=\"\\t\")\n",
    "UD_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(x, label_name):\n",
    "    splitted = x.split(\"#\")\n",
    "    if label_name == \"irony\":\n",
    "        return splitted[2]\n",
    "    elif label_name == \"sarcasm\":\n",
    "        return splitted[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traintest(x):\n",
    "    splitted = x.split(\"#\")\n",
    "    if splitted[0]==\"training\":\n",
    "        return \"training\"\n",
    "    else:\n",
    "        return \"test\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "UD_dataset[\"label_irony\"] = UD_dataset[\"Filename\"].apply(get_labels, label_name = \"irony\")\n",
    "UD_dataset[\"label_sarcasm\"] = UD_dataset[\"Filename\"].apply(get_labels, label_name = \"sarcasm\")\n",
    "UD_dataset[\"type\"] = UD_dataset[\"Filename\"].apply(traintest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>tokens_per_sent</th>\n",
       "      <th>char_per_tok</th>\n",
       "      <th>upos_dist_ADJ</th>\n",
       "      <th>upos_dist_ADP</th>\n",
       "      <th>upos_dist_ADV</th>\n",
       "      <th>upos_dist_AUX</th>\n",
       "      <th>upos_dist_CCONJ</th>\n",
       "      <th>...</th>\n",
       "      <th>subordinate_pre</th>\n",
       "      <th>avg_subordinate_chain_len</th>\n",
       "      <th>subordinate_dist_1</th>\n",
       "      <th>subordinate_dist_2</th>\n",
       "      <th>subordinate_dist_3</th>\n",
       "      <th>subordinate_dist_4</th>\n",
       "      <th>subordinate_dist_5</th>\n",
       "      <th>label_irony</th>\n",
       "      <th>label_sarcasm</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>training#799528852410265600#1#1#HSC.conllu</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.250000</td>\n",
       "      <td>10.526316</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.263158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>training#808400282107445250#0#0#HSC.conllu</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>training#553992006671024129#1#1#HSC.conllu</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>21.428571</td>\n",
       "      <td>14.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>7.142857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>training#531752278152462336#1#0#TW-BS.conllu</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>training#507259632075542528#1#1#TW-BS.conllu</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.680000</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>19.230769</td>\n",
       "      <td>7.692308</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Filename  n_sentences  n_tokens  \\\n",
       "0    training#799528852410265600#1#1#HSC.conllu            1        19   \n",
       "1    training#808400282107445250#0#0#HSC.conllu            2        15   \n",
       "2    training#553992006671024129#1#1#HSC.conllu            1        14   \n",
       "3  training#531752278152462336#1#0#TW-BS.conllu            2        12   \n",
       "4  training#507259632075542528#1#1#TW-BS.conllu            2        26   \n",
       "\n",
       "   tokens_per_sent  char_per_tok  upos_dist_ADJ  upos_dist_ADP  upos_dist_ADV  \\\n",
       "0             19.0      5.250000      10.526316       5.263158       0.000000   \n",
       "1              7.5      7.230769       0.000000      13.333333       0.000000   \n",
       "2             14.0      4.571429      21.428571      14.285714       0.000000   \n",
       "3              6.0      6.181818       0.000000       8.333333       0.000000   \n",
       "4             13.0      4.680000       7.692308      19.230769       7.692308   \n",
       "\n",
       "   upos_dist_AUX  upos_dist_CCONJ  ...  subordinate_pre  \\\n",
       "0       0.000000         5.263158  ...              0.0   \n",
       "1       0.000000         0.000000  ...              0.0   \n",
       "2       7.142857         7.142857  ...              0.0   \n",
       "3       0.000000         8.333333  ...              0.0   \n",
       "4       3.846154         0.000000  ...              0.0   \n",
       "\n",
       "   avg_subordinate_chain_len  subordinate_dist_1  subordinate_dist_2  \\\n",
       "0                        0.0                 0.0                 0.0   \n",
       "1                        0.0                 0.0                 0.0   \n",
       "2                        0.0                 0.0                 0.0   \n",
       "3                        0.0                 0.0                 0.0   \n",
       "4                        1.0               100.0                 0.0   \n",
       "\n",
       "   subordinate_dist_3  subordinate_dist_4  subordinate_dist_5  label_irony  \\\n",
       "0                 0.0                 0.0                 0.0            1   \n",
       "1                 0.0                 0.0                 0.0            0   \n",
       "2                 0.0                 0.0                 0.0            1   \n",
       "3                 0.0                 0.0                 0.0            1   \n",
       "4                 0.0                 0.0                 0.0            1   \n",
       "\n",
       "   label_sarcasm      type  \n",
       "0              1  training  \n",
       "1              0  training  \n",
       "2              1  training  \n",
       "3              0  training  \n",
       "4              1  training  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UD_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = UD_dataset.loc[UD_dataset[\"type\"]==\"training\"]\n",
    "test_df = UD_dataset.loc[UD_dataset[\"type\"]==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = UD_dataset.columns.to_list()[1:]\n",
    "training_set = []\n",
    "test_set = []\n",
    "for index, row in UD_dataset.iterrows():\n",
    "    feature_vals = []\n",
    "    for feature in feature_names:\n",
    "        feature_vals.append(row[feature])\n",
    "    if row[\"type\"]==\"training\":\n",
    "        training_set.append(feature_vals)\n",
    "    else:\n",
    "        test_set.append(feature_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_labels_irony = training_df[\"label_irony\"].to_list()\n",
    "tr_labels_sarcasm = training_df[\"label_sarcasm\"].to_list()\n",
    "ts_labels_irony = test_df[\"label_irony\"].to_list()\n",
    "ts_labels_sarcasm = test_df[\"label_sarcasm\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
