{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATORE SVM LINEARE CON INPUT DI WORD EMBEDDINGS\n",
    "\n",
    "Classificatore basato su svm lineare che prende in input i word embeddings di parole italiane, più specificamente dei word embedding sviluppati per EvalIta 2018 dall'Italian NLP Lab. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re \n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento Word Embeddings\n",
    "\n",
    "Il file txt dei word embedding è stato ottenuto attraverso l'elaborazione di un file sqlite. Per ogni riga (la quale rappresenta una parola) all'interno del file, si crea un record in un dizionario con chiave parola e come valore il vattore che rappresenta il word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per il caricamento degli embedding itwac\n",
    "def load_embeddings():\n",
    "    embeddings_dict = dict()\n",
    "    for line in open('../data/embeddings/itwac32.txt', encoding='utf-8'):\n",
    "        splitted = line.strip().split('\\t')\n",
    "        word = splitted[0]\n",
    "        embedding = splitted[1:]\n",
    "        embedding = [float(val) for val in embedding]\n",
    "        embeddings_dict[word] = np.asarray(embedding)\n",
    "    return embeddings_dict\n",
    "\n",
    "embeddings = load_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02069134,  0.09119736,  0.25785723, -0.23561105, -0.28197852,\n",
       "       -0.13193955, -0.13197723, -0.05229089, -0.28881341,  0.06564969,\n",
       "       -0.30802506,  0.11779311, -0.03571652, -0.08748714, -0.24729131,\n",
       "        0.2577146 ,  0.11925782, -0.27795964,  0.20498367,  0.08414506,\n",
       "        0.08175091, -0.05181665, -0.34403449, -0.05261306,  0.08858071,\n",
       "       -0.09748928,  0.12879393,  0.04387102, -0.04690454,  0.08181785,\n",
       "        0.321078  ,  0.01658573])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['amico']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizzazione del testo \n",
    "\n",
    "Le parole all'interno dei post devono essere normalizzate in questo modo:\n",
    "\n",
    "Numeri:\n",
    "- interi tra 0 e 2100 possono essere mantenuti così come sono\n",
    "- i numeri interi maggiori di 2100 diventano una stringa specifica con un numero che rappresenta il numero di cifre\n",
    "- se non si tratta di numeri interi, si convertono le cifre all'interno della stringa in questa sequenze @Dg\n",
    "\n",
    "Parole:\n",
    "- le parole che iniziano con una lettera maiuscola devono avere prima parola maiuscola e le altre minuscole\n",
    "- le parole che iniziano con una lettera minuscola devono avere tutti i caratteri minuscolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che trasforma le cifre all'interno di un token\n",
    "def digit_norm(word):\n",
    "    try:\n",
    "        val = int(word)\n",
    "    except:\n",
    "        normalized = re.sub('\\d', '@Dg', word)\n",
    "        return normalized\n",
    "    if val >= 0 and val<1200:\n",
    "        return str(val)\n",
    "    else:\n",
    "        return f'DIGLEN_{str(len(str(val)))}'\n",
    "\n",
    "#funzione che normalizza i token\n",
    "def normalize(word):\n",
    "    if \"http\" in word or (\".\" in word and \"/\" in word):\n",
    "        return str(\"___URL___\")\n",
    "    if len(word)>26:\n",
    "        return \"__LONG-LONG__\"\n",
    "    digits = digit_norm(word)\n",
    "    if digits != word:\n",
    "        word = digits\n",
    "    if word[0].isupper():\n",
    "        word = word.capitalize()\n",
    "    else:\n",
    "        word = word.lower()\n",
    "    return word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'Le', 'pos': 'DET'}, {'word': '5', 'pos': 'NUM'}, {'word': 'sgradevoli', 'pos': 'ADJ'}, {'word': 'realtà', 'pos': 'NOUN'}, {'word': 'di', 'pos': 'ADP'}, {'word': 'cui', 'pos': 'PRON'}, {'word': 'Berlusconi', 'pos': 'PROPN'}, {'word': 'dovrebbe', 'pos': 'AUX'}, {'word': 'rendersi', 'pos': 'VERB'}, {'word': 'personalmente', 'pos': 'ADV'}, {'word': 'conto', 'pos': 'NOUN'}, {'word': '<url>', 'pos': 'PROPN'}, {'word': 'Mario', 'pos': 'PROPN'}, {'word': 'Monti', 'pos': 'PROPN'}, {'word': 'non', 'pos': 'ADV'}, {'word': 'usa', 'pos': 'VERB'}, {'word': 'mezzi', 'pos': 'ADJ'}, {'word': 'termini', 'pos': 'NOUN'}]\n"
     ]
    }
   ],
   "source": [
    "#funzione che estrae dai file conllu i token e li normalizza\n",
    "def get_tokens(doc_path):\n",
    "    doc_tokens = []\n",
    "    skip_lines = 0\n",
    "    first = False\n",
    "    for line in open(doc_path, \"r\", encoding=\"utf-8\"):\n",
    "        splitted = line.strip().split(\"\\t\")\n",
    "        if line[0].isdigit():\n",
    "            if skip_lines == 0 and first == False:\n",
    "                if \"-\" not in splitted[0]:\n",
    "                    word = normalize(splitted[1])\n",
    "                    pos=splitted[3]\n",
    "                    token = {'word': word, 'pos': pos}\n",
    "                    doc_tokens.append(token)\n",
    "                else:\n",
    "                    word=normalize(splitted[1])\n",
    "                    skip_lines = len(splitted[0].split('-'))\n",
    "                    first = True\n",
    "            elif skip_lines != 0 and first == True:\n",
    "                pos = splitted[3]\n",
    "                token = {'word': word, 'pos': pos}\n",
    "                doc_tokens.append(token)\n",
    "                skip_lines-=1\n",
    "                first = False\n",
    "            else: \n",
    "                skip_lines-=1\n",
    "    return doc_tokens\n",
    "\n",
    "#funzione che crea il traingset o test set in base all'argomento specificato\n",
    "def create_set(type):\n",
    "    annotated_posts = []\n",
    "    for doc in os.listdir(\"../data/UD_annotation\"):\n",
    "        if type in doc: \n",
    "            doc_path = \"../data/UD_annotation/\" + doc    \n",
    "            doc_tokens = get_tokens(doc_path)\n",
    "            annotated_posts.append(doc_tokens)\n",
    "    return annotated_posts\n",
    "\n",
    "\n",
    "print(get_tokens(\"../data/UD_annotation/training#125642756147265536#0#0#TW-SENTIPOLC.conllu\"))\n",
    "\n",
    "training_set = create_set(\"training\")\n",
    "test_set = create_set(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': '#la@dg', 'pos': 'NUM'},\n",
       " {'word': 'ma', 'pos': 'CCONJ'},\n",
       " {'word': 'perche', 'pos': 'ADV'},\n",
       " {'word': \"'\", 'pos': 'PUNCT'},\n",
       " {'word': 'Mario', 'pos': 'PROPN'},\n",
       " {'word': 'Monti', 'pos': 'PROPN'},\n",
       " {'word': 'non', 'pos': 'ADV'},\n",
       " {'word': 'fa', 'pos': 'VERB'},\n",
       " {'word': 'il', 'pos': 'DET'},\n",
       " {'word': 'premier', 'pos': 'NOUN'},\n",
       " {'word': '?', 'pos': 'PUNCT'},\n",
       " {'word': 'Che', 'pos': 'DET'},\n",
       " {'word': 'persona', 'pos': 'NOUN'},\n",
       " {'word': 'competente', 'pos': 'ADJ'},\n",
       " {'word': 'e', 'pos': 'CCONJ'},\n",
       " {'word': 'per', 'pos': 'ADP'},\n",
       " {'word': 'bene', 'pos': 'ADV'},\n",
       " {'word': '!', 'pos': 'PUNCT'}]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione Features\n",
    "\n",
    "Per fare in modo di avere un vettore di features per ogni sample del nostro dataset, per ogni post vanno estratti gli embedding e aggregati secondo una delle seguenti strategie:\n",
    "- Somma \n",
    "- Media \n",
    "- Prodotto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_embeddings_sum(post_emb):\n",
    "    return np.sum(post_emb, axis=0)\n",
    "\n",
    "def post_embeddings_mean(post_emb):\n",
    "    embeddings_sum = post_embeddings_sum(post_emb)\n",
    "    return np.divide(embeddings_sum, len(post_emb))\n",
    "\n",
    "def post_embeddings_prod(post_emb):\n",
    "    return np.prod(post_emb, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che restituisce gli embedding all'interno di un post e infine li aggrega secondo la strategia definita\n",
    "def get_post_embeddings(post, aggr, consider_pos=[]):\n",
    "    post_emb = []\n",
    "    for token in post:\n",
    "        word = token['word']\n",
    "        pos = token['pos']\n",
    "        if consider_pos == []: \n",
    "            if word in embeddings:\n",
    "                single_embedding = embeddings[word]\n",
    "                post_emb.append(single_embedding)\n",
    "        else:\n",
    "            if word in embeddings and pos in consider_pos:\n",
    "                single_embedding = embeddings[word]\n",
    "                post_emb.append(single_embedding)\n",
    "    if len(post_emb)==0:\n",
    "        post_emb = [np.zeros(32)]\n",
    "    if aggr==\"sum\":\n",
    "        return post_embeddings_sum(post_emb)\n",
    "    if aggr==\"mean\":\n",
    "        return post_embeddings_mean(post_emb)\n",
    "    if aggr==\"prod\":\n",
    "        return post_embeddings_prod(post_emb)\n",
    "\n",
    "#funzione che estrae gli embeddings e li aggrega separatamente per part of speech; infine i tre array vengono concatenati\n",
    "def get_post_embeddings_sep(post, aggr, pos_to_consider):\n",
    "    all_embs = []\n",
    "    for pos in pos_to_consider:\n",
    "        pos_embs = []\n",
    "        for token in post:\n",
    "            word = token['word'] \n",
    "            if token['pos'] == pos and word in embeddings:\n",
    "                pos_embs.append(embeddings[word])\n",
    "        if len(pos_embs) == 0:\n",
    "            pos_embs = [np.zeros(32)]\n",
    "        if aggr==\"sum\":   \n",
    "            pos_aggr = post_embeddings_sum(pos_embs)\n",
    "        if aggr==\"mean\":\n",
    "            pos_aggr = post_embeddings_mean(pos_embs)\n",
    "        if aggr==\"prod\":   \n",
    "            pos_aggr = post_embeddings_prod(pos_embs)\n",
    "        all_embs.append(pos_aggr)\n",
    "    all_pos_embs = np.concatenate(all_embs)\n",
    "    return all_pos_embs\n",
    "\n",
    "\n",
    "#print(f'Media: {post_embeddings_mean(sample)}')\n",
    "#print(f'Somma: {post_embeddings_sum(sample)}')\n",
    "#print(f'Prodotto: {post_embeddings_prod(sample)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features prendendo in considerazione tutte le pos: \n",
      "[ 0.70630973  0.63592037 -1.32889915  0.69488399  0.97954186  0.49242998\n",
      "  0.81090928  0.26945482  0.86591043  0.72883238  0.12078786 -0.96009408\n",
      "  1.22319504 -0.00722711  0.38346463 -0.49809163  0.90218449  0.43854262\n",
      "  1.10390444 -1.22251498  1.2640001   0.58526576 -2.26762946  1.28747057\n",
      "  0.96093598 -0.25486191  0.97472124 -0.47080601 -1.19037909 -0.52221277\n",
      " -0.02316337 -0.47344547]\n"
     ]
    }
   ],
   "source": [
    "sample = get_post_embeddings(training_set[0], \"sum\")\n",
    "print(f'Features prendendo in considerazione tutte le pos: \\n{sample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features prendendo in considerazione le pos aggettivo, verbo e sostantivo: \n",
      "[ 0.7420505  -0.21146497 -0.75577984  0.58708336  0.78234449 -0.08339422\n",
      "  1.04220375 -0.29548807 -0.02251081 -0.11744096 -0.08204558 -0.31968346\n",
      "  0.94269185  0.09774299  0.49471298 -0.72800942  0.4769331   0.37827756\n",
      "  0.2307061  -0.97352124  1.0706808   0.49066386 -1.36544756  0.16201165\n",
      "  0.34403714 -0.87449325 -0.27552854 -0.06722229 -0.60256457 -0.58115096\n",
      " -0.38340611  0.29236167]\n"
     ]
    }
   ],
   "source": [
    "sample = get_post_embeddings(training_set[0], \"sum\", ['ADJ', 'VERB', 'NOUN'])\n",
    "print(f'Features prendendo in considerazione le pos aggettivo, verbo e sostantivo: \\n{sample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features prendendo in considerazione solo pos aggettivo, verbo e sostantivo e concatenando le medie dei loro embeddings: \n",
      "[ 0.33562477 -0.05448548 -0.42705861  0.01437109  0.45159502  0.00348032\n",
      "  0.26449129  0.03243306 -0.08381133 -0.14544163 -0.05085387 -0.11924932\n",
      "  0.38293768 -0.0571368   0.44839092 -0.33565044  0.37418649  0.02131738\n",
      "  0.25892133 -0.28732456  0.60670963  0.151251   -0.54009455  0.04013886\n",
      "  0.04687114 -0.11289249 -0.48268102 -0.13149872 -0.32601021  0.02917017\n",
      " -0.17283661 -0.01268265  0.43814081 -0.10103156 -0.19417439  0.13527741\n",
      " -0.19628561 -0.04956499  0.22108051 -0.14000706 -0.08482647  0.04375442\n",
      "  0.08646346 -0.00164628  0.11506289  0.08473135 -0.06659641  0.10320415\n",
      "  0.23755038 -0.05376894  0.33137974 -0.27062881 -0.07256045  0.08457013\n",
      " -0.08995622 -0.12816061  0.32735649 -0.04310134  0.07824811  0.15233405\n",
      "  0.06438236 -0.14330558  0.15729892  0.33642733 -0.03171508 -0.05594792\n",
      " -0.13454684  0.43743487  0.52703507 -0.03730955  0.55663195 -0.18791406\n",
      "  0.14612699 -0.01575376 -0.11765517 -0.19878786  0.44469127  0.07014844\n",
      "  0.11291848 -0.49556313 -0.13480377  0.41072911 -0.35959498 -0.41556786\n",
      "  0.53653162  0.25484272 -0.73539679  0.2500334  -0.03019049 -0.71849942\n",
      "  0.12890437 -0.08805762 -0.34093672 -0.46701554 -0.36786842 -0.03138301]\n"
     ]
    }
   ],
   "source": [
    "sample = get_post_embeddings_sep(training_set[0], \"sum\", ['ADJ', 'VERB', 'NOUN'])\n",
    "print(f'Features prendendo in considerazione solo pos aggettivo, verbo e sostantivo e concatenando le medie dei loro embeddings: \\n{sample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_description=\"Tutti PoS considerati, embeddings aggregati con somma\"\n",
    "\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    for post in dataset:\n",
    "        post_embeddings = get_post_embeddings_sep(post, \"sum\")\n",
    "        all_features.append(post_embeddings)\n",
    "    return all_features\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_features = get_features(training_set)\n",
    "ts_features = get_features(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "tr_features = scaler.fit_transform(tr_features)\n",
    "ts_features = scaler.transform(ts_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che estrae le labels dal nome del file\n",
    "def create_labels(type):\n",
    "    labels = []\n",
    "    for doc in os.listdir(\"../data/UD_annotation\"):\n",
    "        if type in doc: \n",
    "            splitted = doc.split(\"#\")\n",
    "            irony = splitted[2]\n",
    "            labels.append(irony)\n",
    "    return labels\n",
    "\n",
    "tr_labels = create_labels(\"training\")\n",
    "ts_labels = create_labels(\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation con K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Fold n.1 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.5552763819095478\n",
      "Accuracy della baseline: 0.5062814070351759\n",
      "-------------------------Fold n.2 just started!-------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---> test: \n",
      "Accuracy del modello: 0.5552763819095478\n",
      "Accuracy della baseline: 0.45226130653266333\n",
      "-------------------------Fold n.3 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.5220125786163522\n",
      "Accuracy della baseline: 0.5031446540880503\n",
      "-------------------------Fold n.4 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.5345911949685535\n",
      "Accuracy della baseline: 0.47924528301886793\n",
      "-------------------------Fold n.5 just started!-------------------------\n",
      "---> test: \n",
      "Accuracy del modello: 0.5723270440251572\n",
      "Accuracy della baseline: 0.5069182389937107\n"
     ]
    }
   ],
   "source": [
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "folds = list(splitter.split(tr_features))\n",
    "tr_labels = np.asarray(tr_labels)\n",
    "i=1\n",
    "real_lbls = []\n",
    "predicted = []\n",
    "all_acc = []\n",
    "all_dummy_acc = []\n",
    "\n",
    "for fold in folds:\n",
    "    print(f'-------------------------Fold n.{i} just started!-------------------------')\n",
    "    #si creano i set per ogni fold, training e test\n",
    "    train_index = fold[0]\n",
    "    test_index = fold[1]\n",
    "    #train set\n",
    "    x_train = tr_features[train_index]\n",
    "    y_train = tr_labels[train_index]\n",
    "    #test set\n",
    "    x_test = tr_features[test_index]\n",
    "    y_test = tr_labels[test_index]\n",
    "    #inizio del training\n",
    "    svc = LinearSVC(dual=False)\n",
    "    svc.fit(x_train, y_train)\n",
    "    #predictions\n",
    "    pred = svc.predict(x_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    #usiamo un Dummy Classifier come Baseline\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(x_train, y_train)\n",
    "    dummy_acc = dummy.score(x_test, y_test)\n",
    "    real_lbls+=y_test.tolist()\n",
    "    predicted+=pred.tolist()\n",
    "    all_acc.append(acc)\n",
    "    all_dummy_acc.append(dummy_acc)\n",
    "    print(\"---> test: \")\n",
    "    print(f\"Accuracy del modello: {acc}\\nAccuracy della baseline: {dummy_acc}\")\n",
    "    i+=1\n",
    "\n",
    "def avg(x):\n",
    "    return sum(x)/len(x)\n",
    "\n",
    "'''\n",
    "with open('results_3.txt', 'a') as file:\n",
    "    file.write(f'\\n{info_description}\\n')\n",
    "    for i in range(len(all_acc)):\n",
    "        file.write(f'Risultati Fold {i+1} -->  Accuracy modello: {all_acc[i]} | Accuracy baseline: {all_dummy_acc[i]}  \\n')\n",
    "    file.write(f'Media: {avg(all_acc)}')\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Si testa il modello allenato sul tipo di rappresntazioni che hanno ottenuto la migliore accuratezza durante la Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.43      0.48       437\n",
      "           1       0.52      0.62      0.57       435\n",
      "\n",
      "    accuracy                           0.53       872\n",
      "   macro avg       0.53      0.53      0.52       872\n",
      "weighted avg       0.53      0.53      0.52       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = svc.predict(ts_features)\n",
    "print(classification_report(ts_labels, test_preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x192230692a0>"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(ts_labels, test_preds, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
