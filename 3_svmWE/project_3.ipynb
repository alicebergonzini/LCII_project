{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. CLASSIFICATORE SVM LINEARE CON INPUT DI WORD EMBEDDINGS\n",
    "\n",
    "Classificatore basato su svm lineare che prende in input i word embeddings di parole italiane, più specificamente dei word embedding sviluppati per EvalIta 2018 dall'Italian NLP Lab. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re \n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caricamento Word Embeddings\n",
    "\n",
    "Il file txt dei word embedding è stato ottenuto attraverso l'elaborazione di un file sqlite. Per ogni riga (la quale rappresenta una parola) all'interno del file, si crea un record in un dizionario con chiave parola e come valore il vattore che rappresenta il word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per il caricamento degli embedding itwac\n",
    "def load_embeddings():\n",
    "    embeddings_dict = dict()\n",
    "    for line in open('../data/embeddings/itwac32.txt', encoding='utf-8'):\n",
    "        splitted = line.strip().split('\\t')\n",
    "        word = splitted[0]\n",
    "        embedding = splitted[1:]\n",
    "        embedding = [float(val) for val in embedding]\n",
    "        embeddings_dict[word] = np.asarray(embedding)\n",
    "    return embeddings_dict\n",
    "\n",
    "embeddings = load_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02069134,  0.09119736,  0.25785723, -0.23561105, -0.28197852,\n",
       "       -0.13193955, -0.13197723, -0.05229089, -0.28881341,  0.06564969,\n",
       "       -0.30802506,  0.11779311, -0.03571652, -0.08748714, -0.24729131,\n",
       "        0.2577146 ,  0.11925782, -0.27795964,  0.20498367,  0.08414506,\n",
       "        0.08175091, -0.05181665, -0.34403449, -0.05261306,  0.08858071,\n",
       "       -0.09748928,  0.12879393,  0.04387102, -0.04690454,  0.08181785,\n",
       "        0.321078  ,  0.01658573])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings['amico']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizzazione del testo \n",
    "\n",
    "Le parole all'interno dei post devono essere normalizzate in questo modo:\n",
    "\n",
    "Numeri:\n",
    "- interi tra 0 e 2100 possono essere mantenuti così come sono\n",
    "- i numeri interi maggiori di 2100 diventano una stringa specifica con un numero che rappresenta il numero di cifre\n",
    "- se non si tratta di numeri interi, si convertono le cifre all'interno della stringa in questa sequenze @Dg\n",
    "\n",
    "Parole:\n",
    "- le parole che iniziano con una lettera maiuscola devono avere prima parola maiuscola e le altre minuscole\n",
    "- le parole che iniziano con una lettera minuscola devono avere tutti i caratteri minuscolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che trasforma le cifre all'interno di un token\n",
    "def digit_norm(word):\n",
    "    try:\n",
    "        val = int(word)\n",
    "    except:\n",
    "        normalized = re.sub('\\d', '@Dg', word)\n",
    "        return normalized\n",
    "    if val >= 0 and val<1200:\n",
    "        return str(val)\n",
    "    else:\n",
    "        return f'DIGLEN_{str(len(str(val)))}'\n",
    "\n",
    "#funzione che normalizza i token\n",
    "def normalize(word):\n",
    "    if \"http\" in word or (\".\" in word and \"/\" in word):\n",
    "        return str(\"___URL___\")\n",
    "    if len(word)>26:\n",
    "        return \"__LONG-LONG__\"\n",
    "    digits = digit_norm(word)\n",
    "    if digits != word:\n",
    "        word = digits\n",
    "    if word[0].isupper():\n",
    "        word = word.capitalize()\n",
    "    else:\n",
    "        word = word.lower()\n",
    "    return word\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word': 'Le', 'pos': 'DET'}, {'word': '5', 'pos': 'NUM'}, {'word': 'sgradevoli', 'pos': 'ADJ'}, {'word': 'realtà', 'pos': 'NOUN'}, {'word': 'di', 'pos': 'ADP'}, {'word': 'cui', 'pos': 'PRON'}, {'word': 'Berlusconi', 'pos': 'PROPN'}, {'word': 'dovrebbe', 'pos': 'AUX'}, {'word': 'rendersi', 'pos': 'VERB'}, {'word': 'personalmente', 'pos': 'ADV'}, {'word': 'conto', 'pos': 'NOUN'}, {'word': '<url>', 'pos': 'PROPN'}, {'word': 'Mario', 'pos': 'PROPN'}, {'word': 'Monti', 'pos': 'PROPN'}, {'word': 'non', 'pos': 'ADV'}, {'word': 'usa', 'pos': 'VERB'}, {'word': 'mezzi', 'pos': 'ADJ'}, {'word': 'termini', 'pos': 'NOUN'}]\n"
     ]
    }
   ],
   "source": [
    "#funzione che estrae dai file conllu i token e li normalizza\n",
    "def get_tokens(doc_path):\n",
    "    doc_tokens = []\n",
    "    skip_lines = 0\n",
    "    first = False\n",
    "    for line in open(doc_path, \"r\", encoding=\"utf-8\"):\n",
    "        splitted = line.strip().split(\"\\t\")\n",
    "        if line[0].isdigit():\n",
    "            if skip_lines == 0 and first == False:\n",
    "                #se non si tratta di clitici si memorizza parola e part of speech e si aggiunge alla lista\n",
    "                if \"-\" not in splitted[0]:\n",
    "                    word = normalize(splitted[1])\n",
    "                    pos=splitted[3]\n",
    "                    token = {'word': word, 'pos': pos}\n",
    "                    doc_tokens.append(token)\n",
    "                #nel caso in cui ci fossero dei clitici, memorizza la parola e alla riga dopo salva la part of speech e aggiunge parola e pos alla lista\n",
    "                else:\n",
    "                    word=normalize(splitted[1])\n",
    "                    skip_lines = len(splitted[0].split('-')) #numero di righe da saltare\n",
    "                    first = True\n",
    "            #se si tratta della prima riga da saltare memorizza la part of speech\n",
    "            elif skip_lines != 0 and first == True:\n",
    "                pos = splitted[3]\n",
    "                token = {'word': word, 'pos': pos}\n",
    "                doc_tokens.append(token)\n",
    "                skip_lines-=1\n",
    "                first = False\n",
    "            else: \n",
    "                skip_lines-=1\n",
    "    return doc_tokens\n",
    "\n",
    "#funzione che crea il traingset o test set in base all'argomento specificato\n",
    "def create_set(type):\n",
    "    annotated_posts = []\n",
    "    for doc in os.listdir(\"../data/UD_annotation\"):\n",
    "        if type in doc: \n",
    "            doc_path = \"../data/UD_annotation/\" + doc    \n",
    "            doc_tokens = get_tokens(doc_path)\n",
    "            annotated_posts.append(doc_tokens)\n",
    "    return annotated_posts\n",
    "\n",
    "\n",
    "print(get_tokens(\"../data/UD_annotation/training#125642756147265536#0#0#TW-SENTIPOLC.conllu\"))\n",
    "\n",
    "training_set = create_set(\"training\")\n",
    "test_set = create_set(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': '#la@dg', 'pos': 'NUM'},\n",
       " {'word': 'ma', 'pos': 'CCONJ'},\n",
       " {'word': 'perche', 'pos': 'ADV'},\n",
       " {'word': \"'\", 'pos': 'PUNCT'},\n",
       " {'word': 'Mario', 'pos': 'PROPN'},\n",
       " {'word': 'Monti', 'pos': 'PROPN'},\n",
       " {'word': 'non', 'pos': 'ADV'},\n",
       " {'word': 'fa', 'pos': 'VERB'},\n",
       " {'word': 'il', 'pos': 'DET'},\n",
       " {'word': 'premier', 'pos': 'NOUN'},\n",
       " {'word': '?', 'pos': 'PUNCT'},\n",
       " {'word': 'Che', 'pos': 'DET'},\n",
       " {'word': 'persona', 'pos': 'NOUN'},\n",
       " {'word': 'competente', 'pos': 'ADJ'},\n",
       " {'word': 'e', 'pos': 'CCONJ'},\n",
       " {'word': 'per', 'pos': 'ADP'},\n",
       " {'word': 'bene', 'pos': 'ADV'},\n",
       " {'word': '!', 'pos': 'PUNCT'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrazione Features\n",
    "\n",
    "Per fare in modo di avere un vettore di features per ogni sample del nostro dataset, per ogni post vanno estratti gli embedding e aggregati secondo una delle seguenti strategie:\n",
    "- Somma \n",
    "- Media \n",
    "- Prodotto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le diverse funzioni per aggregare gli embeddings\n",
    "\n",
    "#somma\n",
    "def post_embeddings_sum(post_emb):\n",
    "    return np.sum(post_emb, axis=0)\n",
    "\n",
    "#media\n",
    "def post_embeddings_mean(post_emb):\n",
    "    embeddings_sum = post_embeddings_sum(post_emb)\n",
    "    return np.divide(embeddings_sum, len(post_emb))\n",
    "\n",
    "#prodotto\n",
    "def post_embeddings_prod(post_emb):\n",
    "    return np.prod(post_emb, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che restituisce gli embedding all'interno di un post e infine li aggrega secondo la strategia definita\n",
    "def get_post_embeddings(post, aggr, consider_pos=[]):\n",
    "    post_emb = []\n",
    "    for token in post:\n",
    "        word = token['word']\n",
    "        pos = token['pos']\n",
    "        #se la lista consider_pos è vuota allora si prendono in considerazione tutte le PoS\n",
    "        if consider_pos == []: \n",
    "            if word in embeddings:\n",
    "                single_embedding = embeddings[word]\n",
    "                post_emb.append(single_embedding)\n",
    "        else:\n",
    "            if word in embeddings and pos in consider_pos:\n",
    "                single_embedding = embeddings[word]\n",
    "                post_emb.append(single_embedding)\n",
    "    if len(post_emb)==0:\n",
    "        post_emb = [np.zeros(32)]\n",
    "    #si aggregano gli embedding in base alla funzione passata come argomento\n",
    "    if aggr==\"sum\":\n",
    "        return post_embeddings_sum(post_emb)\n",
    "    if aggr==\"mean\":\n",
    "        return post_embeddings_mean(post_emb)\n",
    "    if aggr==\"prod\":\n",
    "        return post_embeddings_prod(post_emb)\n",
    "\n",
    "#funzione che estrae gli embeddings e li aggrega separatamente per part of speech; infine i tre array vengono concatenati\n",
    "def get_post_embeddings_sep(post, aggr, pos_to_consider):\n",
    "    all_embs = []\n",
    "    for pos in pos_to_consider:\n",
    "        pos_embs = []\n",
    "        for token in post:\n",
    "            word = token['word'] \n",
    "            if token['pos'] == pos and word in embeddings:\n",
    "                pos_embs.append(embeddings[word])\n",
    "        if len(pos_embs) == 0:\n",
    "            pos_embs = [np.zeros(32)]\n",
    "        #per ogni pos si aggregano gli embeddings separatamente\n",
    "        if aggr==\"sum\":   \n",
    "            pos_aggr = post_embeddings_sum(pos_embs)\n",
    "        if aggr==\"mean\":\n",
    "            pos_aggr = post_embeddings_mean(pos_embs)\n",
    "        if aggr==\"prod\":   \n",
    "            pos_aggr = post_embeddings_prod(pos_embs)\n",
    "        all_embs.append(pos_aggr)\n",
    "    all_pos_embs = np.concatenate(all_embs)\n",
    "    return all_pos_embs\n",
    "\n",
    "\n",
    "#print(f'Media: {post_embeddings_mean(sample)}')\n",
    "#print(f'Somma: {post_embeddings_sum(sample)}')\n",
    "#print(f'Prodotto: {post_embeddings_prod(sample)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features prendendo in considerazione tutte le pos: \n",
      "[ 0.70630973  0.63592037 -1.32889915  0.69488399  0.97954186  0.49242998\n",
      "  0.81090928  0.26945482  0.86591043  0.72883238  0.12078786 -0.96009408\n",
      "  1.22319504 -0.00722711  0.38346463 -0.49809163  0.90218449  0.43854262\n",
      "  1.10390444 -1.22251498  1.2640001   0.58526576 -2.26762946  1.28747057\n",
      "  0.96093598 -0.25486191  0.97472124 -0.47080601 -1.19037909 -0.52221277\n",
      " -0.02316337 -0.47344547]\n"
     ]
    }
   ],
   "source": [
    "sample = get_post_embeddings(training_set[0], \"sum\")\n",
    "print(f'Features prendendo in considerazione tutte le pos: \\n{sample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features prendendo in considerazione le pos aggettivo, verbo e sostantivo: \n",
      "[ 0.7420505  -0.21146497 -0.75577984  0.58708336  0.78234449 -0.08339422\n",
      "  1.04220375 -0.29548807 -0.02251081 -0.11744096 -0.08204558 -0.31968346\n",
      "  0.94269185  0.09774299  0.49471298 -0.72800942  0.4769331   0.37827756\n",
      "  0.2307061  -0.97352124  1.0706808   0.49066386 -1.36544756  0.16201165\n",
      "  0.34403714 -0.87449325 -0.27552854 -0.06722229 -0.60256457 -0.58115096\n",
      " -0.38340611  0.29236167]\n"
     ]
    }
   ],
   "source": [
    "sample = get_post_embeddings(training_set[0], \"sum\", ['ADJ', 'VERB', 'NOUN'])\n",
    "print(f'Features prendendo in considerazione le pos aggettivo, verbo e sostantivo: \\n{sample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features prendendo in considerazione solo pos aggettivo, verbo e sostantivo e concatenando le medie dei loro embeddings: \n",
      "[ 0.33562477 -0.05448548 -0.42705861  0.01437109  0.45159502  0.00348032\n",
      "  0.26449129  0.03243306 -0.08381133 -0.14544163 -0.05085387 -0.11924932\n",
      "  0.38293768 -0.0571368   0.44839092 -0.33565044  0.37418649  0.02131738\n",
      "  0.25892133 -0.28732456  0.60670963  0.151251   -0.54009455  0.04013886\n",
      "  0.04687114 -0.11289249 -0.48268102 -0.13149872 -0.32601021  0.02917017\n",
      " -0.17283661 -0.01268265  0.43814081 -0.10103156 -0.19417439  0.13527741\n",
      " -0.19628561 -0.04956499  0.22108051 -0.14000706 -0.08482647  0.04375442\n",
      "  0.08646346 -0.00164628  0.11506289  0.08473135 -0.06659641  0.10320415\n",
      "  0.23755038 -0.05376894  0.33137974 -0.27062881 -0.07256045  0.08457013\n",
      " -0.08995622 -0.12816061  0.32735649 -0.04310134  0.07824811  0.15233405\n",
      "  0.06438236 -0.14330558  0.15729892  0.33642733 -0.03171508 -0.05594792\n",
      " -0.13454684  0.43743487  0.52703507 -0.03730955  0.55663195 -0.18791406\n",
      "  0.14612699 -0.01575376 -0.11765517 -0.19878786  0.44469127  0.07014844\n",
      "  0.11291848 -0.49556313 -0.13480377  0.41072911 -0.35959498 -0.41556786\n",
      "  0.53653162  0.25484272 -0.73539679  0.2500334  -0.03019049 -0.71849942\n",
      "  0.12890437 -0.08805762 -0.34093672 -0.46701554 -0.36786842 -0.03138301]\n"
     ]
    }
   ],
   "source": [
    "sample = get_post_embeddings_sep(training_set[0], \"sum\", ['ADJ', 'VERB', 'NOUN'])\n",
    "print(f'Features prendendo in considerazione solo pos aggettivo, verbo e sostantivo e concatenando le medie dei loro embeddings: \\n{sample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_description=\"Tutti PoS considerati, embeddings aggregati con somma\"\n",
    "\n",
    "#funzione che estrae gli embedding per ogni post\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    for post in dataset:\n",
    "        post_embeddings = get_post_embeddings(post, \"sum\")\n",
    "        all_features.append(post_embeddings)\n",
    "    return all_features\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_features = get_features(training_set)\n",
    "ts_features = get_features(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si scalano i valori delle features\n",
    "scaler = MinMaxScaler()\n",
    "tr_features = scaler.fit_transform(tr_features)\n",
    "ts_features = scaler.transform(ts_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione che estrae le labels dal nome del file\n",
    "def create_labels(type):\n",
    "    labels = []\n",
    "    for doc in os.listdir(\"../data/UD_annotation\"):\n",
    "        if type in doc: \n",
    "            splitted = doc.split(\"#\")\n",
    "            irony = splitted[2]\n",
    "            labels.append(irony)\n",
    "    return labels\n",
    "\n",
    "tr_labels = create_labels(\"training\")\n",
    "ts_labels = create_labels(\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training e Validation con K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Fold n.1 just started!-------------------------\n",
      "Accuracy del modello: 0.6520100502512562\n",
      "Accuracy della baseline: 0.5062814070351759\n",
      "-------------------------Fold n.2 just started!-------------------------\n",
      "Accuracy del modello: 0.6746231155778895\n",
      "Accuracy della baseline: 0.45226130653266333\n",
      "-------------------------Fold n.3 just started!-------------------------\n",
      "Accuracy del modello: 0.690566037735849\n",
      "Accuracy della baseline: 0.5031446540880503\n",
      "-------------------------Fold n.4 just started!-------------------------\n",
      "Accuracy del modello: 0.660377358490566\n",
      "Accuracy della baseline: 0.47924528301886793\n",
      "-------------------------Fold n.5 just started!-------------------------\n",
      "Accuracy del modello: 0.6754716981132075\n",
      "Accuracy della baseline: 0.5069182389937107\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nwith open('results_3.txt', 'a') as file:\\n    file.write(f'\\n{info_description}\\n')\\n    for i in range(len(all_acc)):\\n        file.write(f'Risultati Fold {i+1} -->  Accuracy modello: {all_acc[i]} | Accuracy baseline: {all_dummy_acc[i]}  \\n')\\n    file.write(f'Media: {avg(all_acc)}')\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dividiamo per ogni fold in train e validation set\n",
    "splitter = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "folds = list(splitter.split(tr_features))\n",
    "tr_labels = np.asarray(tr_labels)\n",
    "i=1\n",
    "real_lbls = []\n",
    "predicted = []\n",
    "all_acc = []\n",
    "all_dummy_acc = []\n",
    "\n",
    "for fold in folds:\n",
    "    print(f'-------------------------Fold n.{i} just started!-------------------------')\n",
    "    #si creano i set per ogni fold, training e test\n",
    "    train_index = fold[0]\n",
    "    test_index = fold[1]\n",
    "    #train set\n",
    "    x_train = tr_features[train_index]\n",
    "    y_train = tr_labels[train_index]\n",
    "    #test set\n",
    "    x_test = tr_features[test_index]\n",
    "    y_test = tr_labels[test_index]\n",
    "    #inizio del training\n",
    "    svc = LinearSVC(dual=False)\n",
    "    svc.fit(x_train, y_train)\n",
    "    #predictions\n",
    "    pred = svc.predict(x_test)\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    #usiamo un Dummy Classifier come Baseline\n",
    "    dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "    dummy.fit(x_train, y_train)\n",
    "    dummy_acc = dummy.score(x_test, y_test)\n",
    "    real_lbls+=y_test.tolist()\n",
    "    predicted+=pred.tolist()\n",
    "    all_acc.append(acc)\n",
    "    all_dummy_acc.append(dummy_acc)\n",
    "    print(f\"Accuracy del modello: {acc}\\nAccuracy della baseline: {dummy_acc}\")\n",
    "    i+=1\n",
    "\n",
    "def avg(x):\n",
    "    return sum(x)/len(x)\n",
    "\n",
    "'''\n",
    "with open('results_3.txt', 'a') as file:\n",
    "    file.write(f'\\n{info_description}\\n')\n",
    "    for i in range(len(all_acc)):\n",
    "        file.write(f'Risultati Fold {i+1} -->  Accuracy modello: {all_acc[i]} | Accuracy baseline: {all_dummy_acc[i]}  \\n')\n",
    "    file.write(f'Media: {avg(all_acc)}')\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n",
    "\n",
    "Si testa il modello allenato sul tipo di rappresntazioni che hanno ottenuto la migliore accuratezza durante la Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.62      0.64       437\n",
      "           1       0.64      0.68      0.66       435\n",
      "\n",
      "    accuracy                           0.65       872\n",
      "   macro avg       0.65      0.65      0.65       872\n",
      "weighted avg       0.65      0.65      0.65       872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#si fanno le prediction sul test set e si calcola l'accuracy\n",
    "test_preds = svc.predict(ts_features)\n",
    "print(classification_report(ts_labels, test_preds, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x23954ba7700>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(ts_labels, test_preds, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
